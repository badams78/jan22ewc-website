<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Quality & Scientific Reproducibility Crisis - MacroRoundup</title>
    <link rel="stylesheet" href="../../css/style.css">
    <script src="../../js/visualizations.js" defer></script>
</head>
<body data-subcluster-id="P10_S11">
    <header>
        <div class="container">
            <h1>Research Quality & Scientific Reproducibility Crisis</h1>
            <div class="subtitle">17 articles · Parent: Education & Employment Outcomes</div>
        </div>
    </header>
    
    <div class="container">
        <nav>
            <a href="index.html">← Education & Employment Outcomes</a>
            <a href="../../index.html">Home</a>
            <a href="../../clusters/index.html">All Clusters</a>
        </nav>
        
        <div class="card">
            <h2>Description</h2>
            <p>This subcluster examines systemic problems in academic research quality and scientific integrity that impact economic and educational policy decisions. Articles focus on replication crises, research misconduct, publication bias, and methodological flaws across disciplines. Common sources include peer-reviewed journals like Nature and Science Advances, meta-analyses of research practices, and statistical examinations of publication patterns. Unlike sibling subclusters that analyze educational outcomes or labor market performance directly, this group critiques the underlying research infrastructure that informs those analyses, highlighting how flawed studies, retracted papers, and politicized science compromise evidence-based policymaking in education and employment sectors.</p>
        </div>
        
        <!-- SIMILARITY HEATMAP -->
        <div class="card viz-section">
            <h2>Similarity to All 70 Subclusters</h2>
            <p style="font-size: 0.9rem; color: #666; margin-bottom: 15px;">
                Each cell represents a subcluster. Color intensity shows similarity (blue=low, red=high). 
                Hover for details, click to navigate.
            </p>
            <div id="heatmap-viz" class="heatmap-container"></div>
        </div>
        
        <!-- SPIDER CHART -->
        <div class="card viz-section">
            <h2>Relationship to Primary Clusters</h2>
            <p style="font-size: 0.9rem; color: #666; margin-bottom: 15px;">
                Average similarity to each of the 15 primary clusters. 
                Larger area = stronger relationship to that cluster.
            </p>
            <div id="spider-viz" class="spider-container"></div>
        </div>
        
        <!-- 2D EMBEDDING MAP -->
        <div class="card viz-section">
            <h2>Taxonomy Landscape</h2>
            <p style="font-size: 0.9rem; color: #666; margin-bottom: 15px;">
                All 70 subclusters positioned by similarity (t-SNE). Current subcluster highlighted with border.
                Hover for details, click to navigate.
            </p>
            <div id="embedding-map" class="map-container"></div>
        </div>
        
        <!-- NETWORK GRAPH -->
        <div class="card viz-section">
            <h3 class="collapsible-header" onclick="toggleCollapsible(this)">
                Interactive Network Graph
            </h3>
            <div class="collapsible-content">
                <p style="font-size: 0.9rem; color: #666; margin-bottom: 15px;">
                    Current subcluster at center, connected to related subclusters. 
                    Line thickness = similarity strength. Adjust threshold to show more/fewer connections.
                </p>
                <div id="network-graph" class="network-container"></div>
            </div>
        </div>
        
        <div class="card">
            <h2>Most Representative Articles</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. A 12-point checklist for when to doubt a scientific consensus: recent analyses reveal significant is</div>
            <div class="meta">
                American Enterprise Institute · 2020-09-17
                <span class="similarity">Similarity: 0.81</span>
            </div>
        </li>
        
        <li>
            <div class="title">2. A recent study found 10-20% of results in top American journals may be questionable, raising concern</div>
            <div class="meta">
                The Economist · 2016-01-25
                <span class="similarity">Similarity: 0.79</span>
            </div>
        </li>
        
        <li>
            <div class="title">3. Only 39% of psychology papers published in 2015 were replicable, highlighting a significant issue in</div>
            <div class="meta">
                The Economist · 2016-02-08
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">4. Research in @ScienceAdvances finds papers that fail to replicate receive more citations than those t</div>
            <div class="meta">
                Science · 2021-06-15
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
        <li>
            <div class="title">5. A review of nearly 7,000 empirical economics studies found 90% of studies in half of research areas </div>
            <div class="meta">
                The Economist · 2020-09-17
                <span class="similarity">Similarity: 0.75</span>
            </div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Edge Cases (Boundary Articles)</h2>
            <ul class="article-list">
                
        <li>
            <div class="title">1. Diversity in communities correlates with a decline in social capital, impacting civic engagement & t</div>
            <div class="meta">
                Boston Globe · 2015-04-23
                <span class="similarity">Similarity: 0.57</span>
            </div>
            <div class="meta">Almost classified as: P7_S1</div>
            <div class="edge-reason">This article is borderline for the "Research Quality & Scientific Reproducibility Crisis" cluster because while it presents statistical claims about social capital and diversity that could relate to research quality issues, it focuses primarily on sociological findings about community engagement rather than examining problems with academic research methodology, replication failures, or scientific integrity. The article would be better suited for the "Gender & Age Political Preference Gaps" cluster since it directly addresses civic engagement patterns and voting behavior, which are core political participation topics.</div>
        </li>
        
        <li>
            <div class="title">2. The inspection paradox distorts sample data by overrepresenting larger groups, leading to biased ave</div>
            <div class="meta">
                Science · 2021-08-19
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it discusses a statistical bias that could contribute to research quality issues, it focuses primarily on a specific sampling methodology problem (the inspection paradox) rather than the broader systemic issues of scientific reproducibility, replication crises, or research misconduct that define the cluster's core theme. The article's emphasis on statistical measurement accuracy makes it more aligned with technical analysis methods than with the institutional and procedural problems affecting scientific integrity.</div>
        </li>
        
        <li>
            <div class="title">3. Researchers who narrowly missed securing grants but persisted in reapplying outperformed those who s</div>
            <div class="meta">
                The Economist · 2019-06-06
                <span class="similarity">Similarity: 0.58</span>
            </div>
            <div class="meta">Almost classified as: P10_S1</div>
            <div class="edge-reason">This article is borderline because while it touches on research quality metrics (citations and high-impact papers), it's primarily about grant funding outcomes and researcher performance rather than the core issues of scientific reproducibility, replication crises, or research integrity that define the assigned cluster. The content aligns more closely with performance analysis and management evaluation, which explains its higher similarity to the Management & Performance Analysis cluster.</div>
        </li>
        
            </ul>
        </div>
        
        <div class="card">
            <h2>Original Dendrogram</h2>
            <div class="dendrogram">
                <img src="../../dendrograms/P10_S11_dendrogram.png" alt="Relationship Dendrogram" onerror="this.style.display='none'">
            </div>
        </div>
    </div>
    
    <footer>
        Generated 2026-01-22 · MacroRoundup Taxonomy Analysis v2
    </footer>
</body>
</html>